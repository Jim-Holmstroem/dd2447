\documentclass[a4paper,twoside=false,abstract=false,numbers=noenddot,
titlepage=false,headings=small,parskip=half,version=last]{scrartcl}
\usepackage{../lib/header}
\usepackage{../lib/probability}
\begin{document}
\generateheader{Assignment 2}

\begin{exercise}{A1} Compute $\prob{D|T\in{\text{Polytree}}}$ with Bernoulli
    CPD's \\
    Show how to compute $\prob{D|T}$ where $T$ is a DGM which is a polytree and
    $D = \{x_1,...,x_N\}$ (and $x_i$ is an assignment of values to all
    variables of $T$).
    Assume that all variables are binary and all CPD's Bernoulli.
\end{exercise}
\begin{solution}
    \begin{theorem} Chain rule
    \begin{equation}
        \prob{\textstyle\bigcap_k
        x_k}=\prod_k\cprob{x_k}{\textstyle\bigcap_{j:j<k}x_j}
    \end{equation}
    \end{theorem}
    \begin{proof}
        We can extend the rule 
        \begin{equation}
            \prob{x_i,x_j} = \cprob{x_i}{x_j}\prob{x_j} 
        \end{equation}
        since $x_i,x_j$ is just events we might as well have 
        $x_j=\bigcap_{j'}x_{j'}$ which makes the expression look like this
        \begin{equation}
            \prob{x_i\cap \left(\textstyle\bigcap_{j'}x_{j'}\right)} =
           \cprob{x_i}{\textstyle\bigcap_{j'}x_{j'}}
           \prob{\textstyle\bigcap_{j'}x_{j'}}
        \end{equation}
        by tail-recursion on
        $\prob{\bigcap_{j'}x_{j'}}=\prob{x_a\cap\left(\bigcap_{j'\neq
        a}x_{j'}\right)}$ we will exhaust all $j'$ which leaves us with the
        base-case $\prob{x_a}$. Writing out the entire trace of the recursion
        will gives us the wanted expression for $\prob{\bigcap_k x_k}$.
    \end{proof}
    The first goal is to break down $\cprob{D}{T}$ into the CPD's for each node
    \begin{equation}
        \cprob{D}{T} = \phi
                            \left(
                                \left\{
                                    \cprob{x_t}{\cdot}
                                \right\}_t
                            \right)
    \end{equation}
    this gives an explicit expression for the $\cprob{D}{T}$.

    Since $T$ is a $\text{polytree}\subset\text{DAG}$ it is always possible to 
    sort the data topologically according to $T$.\footnote{How we sort the data
    within a topological level doesn't matter.} 
    We arrange the indices of the data this way so that it will be
    topologically sorted according to $T$ and even if it's bad practice in math we
    replace the old indices with the new sorted ones. This results in
    variables always having the property $i<j\Rightarrow i$ higher up or equally high
    as $j$.\footnote{``higher'' in the context of topological sorting means
    that it is higher up in the sorted DAG that grows downwards.}

    Now apply the chain rule
    \begin{equation}
        \label{eq:chainruled}
        \cprob{D}{T} = \cprob{\left\{x_t\right\}_{k}}{T} = 
        \prod_k\cprob{x_k}{\left\{x_j\right\}_{j:j<k},T}
    \end{equation}

    Next we note that since we have that the data is topologically sorted
    we know that
    \begin{equation}
        \left(D \setminus \left\{x_j\right\}_{j:j<k}\right) \cap
        pa\left(x_k\right) = \emptyset
    \end{equation}
    in other words the parent cannot be at the same or lower topological level.
    This results in 
    \begin{equation}
        \label{eq:superset_parent}
        \left\{x_j\right\}_{j:j<k} \supset pa\left(x_k\right)
    \end{equation}
    which basically states that the parents, denoted 
    $pa(\cdot)$, always is at a higher level.
    
    The next step is to use the conditional independence information from $T$,
    which is that a r.v. is only dependent on the parents r.v.'s\footnote{At
    least for a completely visible graph.}, together with the fact
    \eqref{eq:superset_parent} in \eqref{eq:chainruled} we get 
    \begin{equation}
        \cprob{D}{T} 
        =\prod_k\cprob{x_k}{\left\{x_j\right\}_{j:j<k},T}
        =\prod_k\cprob{x_k}{pa\left(x_k\right)}
    \end{equation}
    Finally since we only have cpt's\footnote{According to mail correspondence with
    the teacher.} $f_t$\footnote{Since each distribution has only two states
    and needs to be normalized
    to 1, this is the same thing as setting $p\in\left(0,1\right)$ in a
    bernoulli}, we have that
    \begin{equation}
        x_t \sim Ber\left(f_t(pa(x_t))\right) 
    \end{equation}
    note that if $pa(x_t)=\emptyset$ then $f_t$ will simply define with one row 
    the probability for $x_t$ directly.
    Now as explicitly written out as possible
    \begin{equation}
        \label{eq:A1}
        \cprob{D}{T}
        =\prod_k\cprob{x_k}{pa\left(x_k\right)}
        =\prod_k
        f_k\left(pa(x_k)\right)^{x_k}(1-f_k\left(pa(x_k)\right))^{1-x_k}
    \end{equation}
    \qed
\end{solution}

\begin{exercise}{A2} Marginalize over non-observed variables \\
    Assume instead that each $x_i$ is an assignment to a subset of the
    variables say $O$.
    Show how to marginalize over $V\setminus O$ (i.e., the non-observed
    variables).
\end{exercise}
\begin{solution}
    Firstly note my syntax for concatenating vectors $a,b$ and indexing the
    concatenation with $k$ looks like this (the order in which they are
    concatenated will never make any difference):
    \begin{equation}
        \left\{a,b\right\}_k
    \end{equation}

    We denote the observed variables with $x_v$ and the hidden with $x_h$, both
    are generally vectors. By general marginalization
    \footnote{$\prob{A}=\sum_{b\in\Omega_B} \prob{A,B=b}$} 
    we have the probability of the observed data 
    \begin{equation}
        \cprob{x_v}{T} = \sum_{x_{h'}\in\prod\left\{0,1\right\}}  \cprob{x_v,x_{h'}}{T}
    \end{equation}
    $\left\{x_v,x_{h'}\right\}$ will together define values for all variables in $T$ which
    gives us completely observed data which in turn makes it possible to use
    \eqref{eq:A1}. This should not be confused with having the data for $x_h$
    in any way, but if we set $x_h = x_{h'}$ we can regard it as
    ``observed''.

    The probability for the observed variables will become
    \begin{equation}
        \cprob{x_v}{T} = \sum_{x_{h'}\in\prod\left\{0,1\right\}}
        \cprob{x_v,x_{h'}}{T} = \sum_{x_{h'}}\prod_k
        \cprob{\left\{x_v,x_{h'}\right\}_k}{pa(\left\{x_v,x_{h'}\right\}_k)}
    \end{equation}
    writing everything explicitly will be really messy but we do it for the
    sake of completeness:
    \begin{equation}
        \cprob{x_v}{T} = 
\sum_{x_{h'}\in\prod\left\{0,1\right\}}
        \prod_k f_k
            \left(
                pa(
                    \left\{x_v,x_{h'}\right\}_k
                )
            \right)
            ^{\left\{x_v,x_{h'}\right\}_k}
            (1-f_k
                \left(
                pa(
                    \left\{x_v,x_{h'}\right\}_k
                )
            \right)
            )^{1-\left\{x_v,x_{h'}\right\}_k}
    \end{equation}

    \qed

\end{solution}

\begin{exercise}{11.3} EM for the mixtures of Bernoullis\\ 
    \begin{itemize}
        \item Show that the M step for ML estimation of a mixture of Bernoullis
            is given by
            \begin{equation}
                \label{eq:EM_ML_Ber}
                \mu_{kj} = 
                \frac
                {
                    \sum_i{
                        r_{ik}x_{ij}
                    }
                }
                {
                \sum_i{
                    r_{ik}
                }
            } 
            \end{equation}
        \item Show that the M step for MAP estimation of a mixture of
        Bernoullis with a $\beta(\alpha,\beta)$ prior is given by
            \begin{equation}
                \label{eq:EM_MAP_Ber}
                \mu_{kj} = 
                \frac
                {
                    (\sum_i{
                        r_{ik}x_{ij}
                    }) + \alpha - 1
                }
                {
                    (\sum_i{
                        r_{ik}
                    }) + \alpha + \beta - 2
                }
            \end{equation}
    \end{itemize}
\end{exercise}
\begin{solution}
    The M step is to optimize the auxiliary function $Q$ with respect to
    $\pi,\theta'$. $Q$ is the expected posterior log-likelihood\footnote{In the
    book it's actually just log-likelihood, but this will work in the same way 
    instead of using $Q(\theta',\theta)+\log\prob{\theta'}$ without derivation,
    we will use posterior-Q as Q instead.} with respect 
    to the last  parameter $\theta$ and the observed data $D$. 
    \footnote{It can be shown that $Q$ is so that the new parameters is always
    better or as good as the last one, but exclude the proof for this since
    it's not needed by the exercise.}
    The expression for this is
    \begin{eqnarray}
        Q(\theta', \theta) = 
        \Expected\left[\log\LL_{MAP}(\theta')|D,\theta\right] =
        \Expected\left[\log\left(\LL(\theta')\prob{\theta'}\right)|D,\theta\right]=\\=
        \Expected\left[\ell(\theta') + \log\prob{\theta'}|D,\theta\right]=
        \Expected\left[\ell(\theta') |D,\theta\right] + \log\prob{\theta'}
    \end{eqnarray}
    and to derive this expression 
    we introducing the latent variable $z_i$ which corresponds to the
    hidden or missing
    variables which basically is the $r.v.$ for how $x_i$
    belongs to the class $k$. \footnote{Responsibility $r_{ik}\eqdef
    \cprob{z_i=k}{x_i,\theta}$}
    We start with MAP and then derive ML by setting a uniform priori.
    \begin{equation}
       Q(\theta', \theta) = 
       \Expected\left[\sum\limits_i\log
       \cprob{x_i,z_i}{\theta'}\right] + \prob{\theta'} =
    \end{equation}
    since $\Expected$ is linear and we can factor on the different classes and
    the factors become given with the parameters $(\pi_k,\theta'_k)$ of class $k$:
    \begin{equation}
       =\sum\limits_i\left[ \Expected 
            \log\left(
                \prod\limits_k{(
                    \pi_k\cprob{x_i}{\theta'_k}
                )^{\II(z_i=k)}}
            \right)
        \right] + \log\prod\limits_k\prob{\theta'_k} = 
    \end{equation}
    then log the inner parts and let $\Expected$ operate on the expression 
    \begin{equation}
        =\sum\limits_i\sum\limits_k\bigg[ \Expected
            \left[
                \II(z_i=k)
            \right]
            \log\left[
                \cprob{x_i}{\theta'_k}
            \right]\bigg] + \sum\limits_k\log\prob{\theta'_k} = 
    \end{equation}
    then we have that the expected $\Expected\left[\II(z_i=k)\right]$ will be
    $\cprob{z_i=k}{x_i,\theta}=r_{ik}$ which is the expected class-belonging of
    $x_i$ given the previous parameters $\theta$.
    The log product rule gives us
    \begin{equation}
        = \sum\limits_i \sum\limits_k {r_{ik}\log \pi_k} +
        \sum\limits_i \sum\limits_k \left\{ r_{ik} \log \cprob{x_i}{\theta'_k}
        \right\} + 
        \sum\limits_k\log\prob{\theta'_k}
    \end{equation}
    
    Now since we have that 
    $\sum\limits_{i,k}r_{ik}\log\pi_k 
    \perp
    \sum\limits_{i,k}
        \left\{
            r_{ik}\log\cprob{x_i}{\theta'_k}
        \right\}+
        \sum\limits_k\log\prob{\theta'_k}$ 
    we can optimize the parameters
    $\pi_k$ and $\theta'_k$ separately and only the $\theta'_k$-term is asked for in the
    exercise which we denote $\ell(\theta'_k)$.

    The model parameters in this case is denoted by $\mu_k$ which is a vector
    and in index-notation $\mu_{kj}$.
    \footnote{Not using Einstein notation for tensor product.}

    We start with the MAP
    \begin{equation}
        \hat{\mu}'_k = 
        \argmax
        {
            \mu'_k
        }{
            \left\{
                \sum\limits_i
                    \left\{
                        r_{ik}\log\cprob{x_i}{\mu'_k}
                    \right\}
                +\log\prob{\mu'_k}
            \right\}
        }
    \end{equation}
    which we find by $\partdev{\ell(\mu'_k)}{\mu'_k}=0$, where 
    $\cprob{x_i}{\mu'_k}=\prod_j \cprob{x_{ij}}{\mu'_{kj}}$ 
    is the multivariate Bernoulli\footnote{Often called multinoulli.}
    distribution for class $k$. The priori in the same way is
    $\prob{\mu'_k}=\prod_j{\prob{\mu'_{kj}}}$.
    In our case for MAP this is $\beta(\alpha,\beta)
    =\frac{{\mu'_{kj}}^{\alpha-1}(1-\mu'_{kj})^{\beta-1}}{B(\alpha,\beta)}$.

    \begin{eqnarray}
        \label{eq:MAP_general}
        \partdev{
            \left(
                \ell(\mu'_k)
            \right)
        }
        {
            \mu'_{kj}
        } = 
        \partdev{
            \sum\limits_i\left\{
                r_{ik}\log \prod\limits_{j'} 
                \cprob{x_{ij'}}{\mu'_{kj'}}\right\}
            + \log\prod\limits_{j'} \prob{\mu'_{kj'}}
        }
        {
            \mu'_{kj} 
        }=\\=
        \partdev{
            \sum\limits_{i,j'}\left\{r_{ik}\log\cprob{x_{ij'}}{\mu'_{kj'}}\right\}
            + \sum\limits_{j'}\log\prob{\mu'_{kj'}}
        }
        {
            \mu'_{kj}
        }=\\=
        \left\{
            \partdev{
                \sum\limits_{j\neq j'} (\cdot)
            }
            {
                \mu'_{kj}
            } = 0
        \right\} = 
        \partdev{
            \sum\limits_i 
            \left\{
                r_{ik}\log 
                \left(
                    {\mu'_{kj}}^{x_{ij}}
                    (1-{\mu'_{kj}})^{(1-x_{ij})}
                \right)
            \right\}
            + \log\frac{
                    {\mu'_{kj}}^{\alpha-1} (1-\mu'_{kj})^{\beta-1}
                }{
                    B(\alpha,\beta)
                }
        }
        {
            \mu'_{kj}
        }
        = \\ = 
        \partdev{
            \sum\limits_i r_{ik}\left(x_{ij}\log{\mu'_{kj}} +
            (1-x_{ij})\log({1-\mu'_{kj}})\right)
        }
        {
            \mu'_k  
        }
        + \\ + 
        \partdev{
            (\alpha-1)\log\mu'_{kj}+(\beta-1)\log(1-\mu'_{kj})-\log B
        }
        {
            \mu'_k  
        }
        = \\ = 
        \frac{\left(\sum_i r_{ik}   x_{ij} \right)+\alpha-1}{  \mu'_{kj}} -
        \frac{\left(\sum_i r_{ik}(1-x_{ij})\right)+ \beta-1}{1-\mu'_{kj}} 
        = \\ =
        \frac{
            (1-\mu'_{kj})\left(\sum_i r_{ik}x_{ij}\right)-
            \mu'_{kj}\left(\sum_i r_{ik}(1-x_{ij})\right)
        }
        {
            \mu'_{kj}(1-\mu'_{kj}) 
        } + \\ +
        \frac
        {
            (1-\mu'_{kj})\left(\alpha-1\right)-
            \mu'_{kj}\left(\beta-1\right)
        }
        {
            \mu'_{kj}(1-\mu'_{kj}) 
        } = \\ =
        \frac
        {
            \left(\sum_i r_{ik}x_{ij}\right) - 
            \mu'_{kj}\left(\sum_i r_{ik}\right) +
            (\alpha-1)-\mu'_{kj}(\alpha+\beta-2)
        }
        {
            \mu'_{kj}(1-\mu'_{kj}) 
        }
    \end{eqnarray}
    and now find the zero of this expression
    \begin{equation}
       \frac
        {
            \left(\sum_i r_{ik}x_{ij}\right) - 
            \mu'_{kj}\left(\sum_i r_{ik}\right) +
            (\alpha-1)-\mu'_{kj}(\alpha+\beta-2)
        }
        {
            \mu'_{kj}(1-\mu'_{kj}) 
        } = 0
    \end{equation}
    \begin{equation}
        \left(\textstyle\sum_i r_{ik}x_{ij}\right) - 
        \mu'_{kj}\left(\textstyle\sum_i r_{ik}\right) +
        (\alpha-1)-\mu'_{kj}(\alpha+\beta-2)
         = 0
    \end{equation}
    \begin{equation}
        \mu'_{kj} \left[\left(\textstyle\sum_i r_{ik}\right)+\alpha+\beta-2\right] 
        = \left(\textstyle\sum_i r_{ik} x_{ij}\right)+\alpha-1
    \end{equation}
    \begin{equation}
        \mu'_{kj} = \frac{
            \left(\sum_i r_{ik} x_{ij}\right)+\alpha-1
        }
        {
            \left(\sum_i r_{ik}\right)+\alpha+\beta-2
        }
    \end{equation}

    which is the same as the equation \eqref{eq:EM_MAP_Ber}.\qed
   
    By just looking at the expression for $\beta(\cdot)$ we see that
    \begin{equation}
        \beta(1,1) = U(0,1) 
    \end{equation}
    and knowing that ML is a MAP with a uniform priori we can just set
    $\alpha,\beta=1$ in the derived expression to get the ML.
    \begin{equation}
        \mu'_{kj} =
        \frac{\left(\sum_ir_{ik}x_{ij}\right)+1-1}{\left(\sum_ir_{ik}\right)+1+1-2} =
        \frac{\sum_ir_{ik}x_{ij}}{\sum_ir_{ik}}
    \end{equation}
    which is the same as the equation \eqref{eq:EM_ML_Ber}.\qed

\end{solution}

%-----------------------
\end{document}
